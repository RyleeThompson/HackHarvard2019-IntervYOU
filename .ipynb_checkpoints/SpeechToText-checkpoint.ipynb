{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "\n",
    "# Imports the Google Cloud client library\n",
    "from google.cloud import speech\n",
    "from google.cloud.speech import enums\n",
    "from google.cloud.speech import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = r\"C:\\Users\\rylee\\GCloud\\Path.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: hi my name is very sticky so I'm sitting across my friend Emile Suarez and Riley Thompson I don't know what I'm doing the I don't know what I'm doing there's a fridge sale across from me and I'm unhappy\n",
      "Transcript:  yeah so I don't know about you but I'm feeling 22\n"
     ]
    }
   ],
   "source": [
    "# Instantiates a client\n",
    "client = speech.SpeechClient()\n",
    "\n",
    "# The name of the audio file to transcribe\n",
    "file_name = os.path.join(\n",
    "    os.getcwd(),\n",
    "    'harvard123.flac')\n",
    "\n",
    "# Loads the audio into memory\n",
    "with io.open(file_name, 'rb') as audio_file:\n",
    "    content = audio_file.read()\n",
    "    audio = types.RecognitionAudio(content=content)\n",
    "\n",
    "config = types.RecognitionConfig(\n",
    "    encoding=enums.RecognitionConfig.AudioEncoding.FLAC,\n",
    "    audio_channel_count = 2,\n",
    "    language_code='en-US')\n",
    "\n",
    "# Detects speech in the audio file\n",
    "response = client.recognize(config, audio)\n",
    "\n",
    "for result in response.results:\n",
    "    print('Transcript: {}'.format(result.alternatives[0].transcript))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hi my name is very sticky so I'm sitting across my friend Emile Suarez and Riley Thompson I don't know what I'm doing the I don't know what I'm doing there's a fridge sale across from me and I'm unhappy. yeah so I don't know about you but I'm feeling 22.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textData = str()\n",
    "for result in response.results:\n",
    "    textData += result.alternatives[0].transcript\n",
    "    textData += '.'\n",
    "textData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.open('answer.txt', 'w+') as text_file:\n",
    "    text_file.write(textData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "audio = AudioSegment.from_file(\"poo2.flac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-76-7e1e31b8ea3f>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-76-7e1e31b8ea3f>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    def getAudioInput(outputFile, CHUNK = 2048, FORMAT = pyaudio.paInt16, CHANNELS = 2, RATE = 48000, RECORD_SECONDS = 5:\u001b[0m\n\u001b[1;37m                                                                                                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "##asdfasdfasdfasdfasdf\n",
    "import wave\n",
    "import pyaudio\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "def getAudioInput(outputFile, CHUNK = 2048, FORMAT = pyaudio.paInt16, CHANNELS = 2, RATE = 48000, RECORD_SECONDS = 5:\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "    print(\"* recording\")\n",
    "\n",
    "    frames = []\n",
    "    means = np.array([])\n",
    "    counter = 0\n",
    "\n",
    "    for j in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "        wf = wave.open('notUsed.wav', 'wb')\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE)\n",
    "        wf.writeframes(b''.join([data, data]))\n",
    "        wf.close()\n",
    "        audio = AudioSegment.from_file('notUsed.wav')\n",
    "        x = np.abs(audio.get_array_of_samples())/2\n",
    "        means = np.append(means, np.mean(x))\n",
    "        if np.mean(x) <= 250:\n",
    "            counter += 1\n",
    "        else:\n",
    "            counter = 0\n",
    "        if counter >= 10000:\n",
    "            break\n",
    "\n",
    "    print(\"* done recording\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    \n",
    "    wf = wave.open(outputFile, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* recording\n",
      "* done recording\n"
     ]
    }
   ],
   "source": [
    "####asdffffffffffff\n",
    "getAudioInput('poo2.flac', RECORD_SECONDS = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = AudioSegment.from_file(\"poo2.flac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAudioList(audio, audioL, Rate):\n",
    "    if audio.frame_count() // Rate > 59:\n",
    "        audioL.append(audio.get_sample_slice(0, Rate * 60))\n",
    "        audio = audio.get_sample_slice(Rate * 60)\n",
    "        getAudioList(audio, audioL, Rate)\n",
    "    else:\n",
    "        audioL.append(audio)\n",
    "    return audioL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "audioList = getAudioList(audio, [], 48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, i in zip(audioList, range(len(audioList))):\n",
    "    a.export(os.getcwd() + r'\\buttmunch' + str(i) + '.flac', format = 'flac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = AudioSegment.from_file(\"poo2.flac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81919.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio.get_sample_slice(1).frame_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81920.0\n",
      "81920.0\n"
     ]
    }
   ],
   "source": [
    "audioList = [audio, audio]\n",
    "for a in audioList:\n",
    "    print(a.frame_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method get_sample_slice in module pydub.audio_segment:\n",
      "\n",
      "get_sample_slice(start_sample=None, end_sample=None) method of pydub.audio_segment.AudioSegment instance\n",
      "    Get a section of the audio segment by sample index.\n",
      "    \n",
      "    NOTE: Negative indices do *not* address samples backword\n",
      "    from the end of the audio segment like a python list.\n",
      "    This is intentional.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(audio.get_sample_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    getAudioInput('test' + str(i) + '.flac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "audio3 = AudioSegment.from_file('test0.flac')\n",
    "for i in range(1, 5):\n",
    "    audio2 = AudioSegment.from_file('test' + str(i) + '.flac')\n",
    "    audio3 = audio3.append(audio2)\n",
    "audio3.export(os.getcwd() + '\\poo.flac', format = 'flac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Synthesizes speech from the input string of text or ssml.\n",
    "\n",
    "Note: ssml must be well-formed according to:\n",
    "    https://www.w3.org/TR/speech-synthesis/\n",
    "\"\"\"\n",
    "from google.cloud import texttospeech\n",
    "\n",
    "# Instantiates a client\n",
    "client = texttospeech.TextToSpeechClient()\n",
    "\n",
    "# Set the text input to be synthesized\n",
    "synthesis_input = texttospeech.types.SynthesisInput(text=\"Can you tell me more about your experience at Denso??\")\n",
    "\n",
    "# Build the voice request, select the language code (\"en-US\") and the ssml\n",
    "# voice gender (\"neutral\")\n",
    "voice = texttospeech.types.VoiceSelectionParams(\n",
    "    language_code='en-US',\n",
    "    ssml_gender=texttospeech.enums.SsmlVoiceGender.NEUTRAL)\n",
    "\n",
    "# Select the type of audio file you want returned\n",
    "audio_config = texttospeech.types.AudioConfig(\n",
    "    audio_encoding=texttospeech.enums.AudioEncoding.MP3)\n",
    "\n",
    "# Perform the text-to-speech request on the text input with the selected\n",
    "# voice parameters and audio file type\n",
    "response = client.synthesize_speech(synthesis_input, voice, audio_config)\n",
    "\n",
    "# The response's audio_content is binary.\n",
    "with open('output.mp3', 'wb') as out:\n",
    "    # Write the response to the output file.\n",
    "    out.write(response.audio_content)\n",
    "    print('Audio content written to file \"output.mp3\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(AudioSegment.get_array_of_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = audio.get_array_of_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.amin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "def sentiment_analyzer_scores(sentence):\n",
    "    score = analyser.polarity_scores(sentence)\n",
    "    print(\"{:-<40} {}\".format(sentence, str(score)))\n",
    "sentiment_analyzer_scores(\"The phone is super cool.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser.sentiment_valence(\"The phone is super cool.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
